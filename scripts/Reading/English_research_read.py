#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒ»å­¦æ–‡çŒ®é˜…è¯»åŠ©æ‰‹
ç”¨äºå¸®åŠ©åŒ»å­¦ç”Ÿé«˜æ•ˆé˜…è¯»å’Œåˆ†æè‹±æ–‡åŒ»å­¦æ–‡çŒ®

éœ€è¦å®‰è£…çš„ä¾èµ–åŒ…:
pip install PyPDF2 requests
"""

# ====================================
# ğŸ“ ç”¨æˆ·é…ç½®åŒºåŸŸ - è¯·åœ¨è¿™é‡Œä¿®æ”¹ä½ çš„è®¾ç½®
# ====================================

# PDFæ–‡ä»¶è·¯å¾„ - å¡«å†™ä½ è¦åˆ†æçš„PDFæ–‡ä»¶å®Œæ•´è·¯å¾„
PDF_FILE_PATH = "D:\AI\Rsearch\Reading\App_of_AI_form2009to2024.pdf"  # ä½¿ç”¨æ­£æ–œæ 

# ç ”ç©¶ä¸»é¢˜ - æè¿°ä½ å½“å‰çš„ç ”ç©¶æ–¹å‘æˆ–æ„Ÿå…´è¶£çš„é¢†åŸŸ
# å¿ƒè¡€ç®¡ç–¾ç—…çš„è¯ç‰©æ²»ç–—æœºåˆ¶
RESEARCH_TOPIC = "å¯¹medical image analyzeäº§ç”Ÿæ•´ä½“æ€§çš„è®¤è¯†"

# OpenRouter APIé…ç½®
API_KEY = "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"  # è¯·å¡«å†™ä½ çš„OpenRouter APIå¯†é’¥
BASE_URL = "https://openrouter.ai/api/v1"  # ä¸€èˆ¬ä¸éœ€è¦ä¿®æ”¹

# ä½¿ç”¨çš„AIæ¨¡å‹ - æ ¹æ®éœ€æ±‚å’Œé¢„ç®—é€‰æ‹©
# æ¨èé€‰é¡¹ï¼š
# - "anthropic/claude-3-haiku" (ä¾¿å®œï¼Œé€Ÿåº¦å¿«ï¼Œé€‚åˆæ—¥å¸¸ä½¿ç”¨)
# - "anthropic/claude-3-sonnet" (ä¸­ç­‰ä»·æ ¼ï¼Œè´¨é‡å¥½ï¼Œæ¨è)
# - "anthropic/claude-3-opus" (æœ€è´µä½†è´¨é‡æœ€é«˜ï¼Œç”¨äºé‡è¦è®ºæ–‡)
# - "openai/gpt-4o" (OpenAIçš„æ¨¡å‹)
# google/gemini-2.5-flash-lite
# anthropic/claude-3.7-sonnet
MODEL = "google/gemini-2.5-flash-lite"

# ====================================
# ä»¥ä¸‹ä¸ºç¨‹åºä»£ç ï¼Œä¸€èˆ¬ä¸éœ€è¦ä¿®æ”¹
# ====================================

import pypdf
import requests
import json
import re
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime

class MedicalPaperReader:
    """åŒ»å­¦æ–‡çŒ®é˜…è¯»åŠ©æ‰‹ä¸»ç±»"""
    
    def __init__(self, api_key: str, base_url: str = "https://openrouter.ai/api/v1"):
        """
        åˆå§‹åŒ–é˜…è¯»åŠ©æ‰‹
        
        Args:
            api_key: OpenRouter APIå¯†é’¥
            base_url: APIåŸºç¡€URL
        """
        self.api_key = api_key
        self.base_url = base_url
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """
        ä»PDFæ–‡ä»¶æå–æ–‡æœ¬å†…å®¹
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            æå–çš„æ–‡æœ¬å†…å®¹
        """
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = pypdf.PdfReader(file)
                text = ""
                
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        page_text = page.extract_text()
                        text += f"\n--- ç¬¬{page_num + 1}é¡µ ---\n{page_text}\n"
                    except Exception as e:
                        print(f"è­¦å‘Š: ç¬¬{page_num + 1}é¡µæå–å¤±è´¥: {e}")
                        continue
                
                return text
        
        except Exception as e:
            raise Exception(f"PDFæ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    
    def split_text_into_chunks(self, text: str, max_chunk_size: int = 6000) -> List[str]:
        """
        å°†é•¿æ–‡æœ¬åˆ†å‰²æˆé€‚åˆAPIå¤„ç†çš„å°å—
        
        Args:
            text: å®Œæ•´æ–‡æœ¬
            max_chunk_size: æ¯å—æœ€å¤§å­—ç¬¦æ•°
            
        Returns:
            æ–‡æœ¬å—åˆ—è¡¨
        """
        # ä¼˜å…ˆæŒ‰æ®µè½åˆ†å‰²
        paragraphs = text.split('\n\n')
        chunks = []
        current_chunk = ""
        
        for paragraph in paragraphs:
            if len(current_chunk) + len(paragraph) + 2 <= max_chunk_size:
                current_chunk += paragraph + "\n\n"
            else:
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                current_chunk = paragraph + "\n\n"
        
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def call_openrouter_api(self, prompt: str, model: str = "anthropic/claude-3-haiku") -> str:
        """
        è°ƒç”¨OpenRouter API
        
        Args:
            prompt: æç¤ºè¯
            model: ä½¿ç”¨çš„æ¨¡å‹
            
        Returns:
            APIå“åº”å†…å®¹
        """
        url = f"{self.base_url}/chat/completions"
        
        payload = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.3,
            "max_tokens": 4000
        }
        
        try:
            response = requests.post(url, headers=self.headers, json=payload, timeout=60)
            response.raise_for_status()
            
            result = response.json()
            return result['choices'][0]['message']['content']
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"APIè¯·æ±‚å¤±è´¥: {e}")
        except KeyError as e:
            raise Exception(f"APIå“åº”æ ¼å¼é”™è¯¯: {e}")
    
    def analyze_paper_structure(self, text: str, research_topic: str, model: str) -> Dict[str, str]:
        """
        åˆ†æè®ºæ–‡ç»“æ„å¹¶ç”Ÿæˆä¸­æ–‡å¤§çº²
        
        Args:
            text: è®ºæ–‡æ–‡æœ¬
            research_topic: ç ”ç©¶ä¸»é¢˜
            model: ä½¿ç”¨çš„æ¨¡å‹
            
        Returns:
            åŒ…å«å¤§çº²å’Œåˆ†æç»“æœçš„å­—å…¸
        """
        prompt = f"""
ä½œä¸ºä¸€åèµ„æ·±åŒ»å­¦æ•™æˆï¼Œè¯·åˆ†æä»¥ä¸‹è‹±æ–‡åŒ»å­¦æ–‡çŒ®ï¼Œç”¨æˆ·çš„ç ”ç©¶ä¸»é¢˜æ˜¯ï¼š{research_topic}

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š

1. **è®ºæ–‡åŸºæœ¬ä¿¡æ¯**
   - æ ‡é¢˜ï¼ˆä¸­è‹±æ–‡ï¼‰
   - ä¸»è¦ä½œè€…å’Œæœºæ„
   - å‘è¡¨æœŸåˆŠå’Œæ—¶é—´
   - ç ”ç©¶ç±»å‹ï¼ˆå¦‚ï¼šéšæœºå¯¹ç…§è¯•éªŒã€ç³»ç»Ÿè¯„ä»·ã€ç—…ä¾‹æŠ¥å‘Šç­‰ï¼‰

2. **ä¸­æ–‡ç»“æ„å¤§çº²**
   æŒ‰ç…§è®ºæ–‡åŸæœ‰ç»“æ„ï¼Œæä¾›è¯¦ç»†çš„ä¸­æ–‡å¤§çº²ï¼ŒåŒ…æ‹¬ï¼š
   - å„ä¸»è¦ç« èŠ‚æ ‡é¢˜çš„ä¸­æ–‡ç¿»è¯‘
   - æ¯ä¸ªç« èŠ‚çš„ä¸»è¦å†…å®¹æ¦‚è¿°
   - é‡è¦çš„å­ç« èŠ‚

3. **ä¸ç ”ç©¶ä¸»é¢˜çš„å…³è”æ€§åˆ†æ**
   - è¯¥æ–‡çŒ®ä¸ç”¨æˆ·ç ”ç©¶ä¸»é¢˜çš„ç›¸å…³ç¨‹åº¦
   - å¯¹ç”¨æˆ·ç ”ç©¶æœ‰ä»·å€¼çš„å…·ä½“å†…å®¹
   - å¯èƒ½çš„å±€é™æ€§

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œæ ¼å¼æ¸…æ™°ï¼Œä¾¿äºåŒ»å­¦ç”Ÿç†è§£ã€‚

è®ºæ–‡å†…å®¹ï¼š
{text[:8000]}...
"""
        
        return {
            "outline": self.call_openrouter_api(prompt, model),
            "research_topic": research_topic
        }
    
    def generate_reading_guide(self, text: str, research_topic: str, model: str) -> str:
        """
        ç”Ÿæˆé’ˆå¯¹æ€§é˜…è¯»æŒ‡å¯¼
        
        Args:
            text: è®ºæ–‡æ–‡æœ¬
            research_topic: ç ”ç©¶ä¸»é¢˜
            model: ä½¿ç”¨çš„æ¨¡å‹
            
        Returns:
            é˜…è¯»æŒ‡å¯¼å†…å®¹
        """
        prompt = f"""
ä½œä¸ºåŒ»å­¦å¯¼å¸ˆï¼Œè¯·ä¸ºæ­£åœ¨ç ”ç©¶"{research_topic}"çš„åŒ»å­¦ç”Ÿæä¾›è¿™ç¯‡æ–‡çŒ®çš„é˜…è¯»æŒ‡å¯¼ã€‚

è¯·æä¾›ï¼š

1. **é˜…è¯»ç­–ç•¥å»ºè®®**
   - å»ºè®®çš„é˜…è¯»é¡ºåº
   - åº”è¯¥é‡ç‚¹å…³æ³¨çš„ç« èŠ‚
   - å¯ä»¥å¿«é€Ÿæµè§ˆçš„éƒ¨åˆ†

2. **å…³é”®æ¦‚å¿µè§£é‡Š**
   - æ–‡ä¸­é‡è¦çš„åŒ»å­¦æœ¯è¯­ï¼ˆè‹±æ–‡+ä¸­æ–‡ï¼‰
   - å…³é”®çš„ç ”ç©¶æ–¹æ³•å’Œç»Ÿè®¡æ¦‚å¿µ
   - éœ€è¦è¡¥å……çš„èƒŒæ™¯çŸ¥è¯†

3. **æ‰¹åˆ¤æ€§æ€ç»´å¼•å¯¼**
   - è¯„ä¼°ç ”ç©¶è®¾è®¡çš„è¦ç‚¹
   - ç»“æœè§£é‡Šçš„æ³¨æ„äº‹é¡¹
   - ä¸´åºŠåº”ç”¨çš„è€ƒé‡

4. **ä¸ä½ ç ”ç©¶çš„å…³è”**
   - è¿™ç¯‡æ–‡çŒ®å¦‚ä½•æ”¯æŒæˆ–æŒ‘æˆ˜ä½ çš„ç ”ç©¶æ–¹å‘
   - å¯ä»¥å€Ÿé‰´çš„ç ”ç©¶æ–¹æ³•
   - å€¼å¾—è¿›ä¸€æ­¥æ¢è®¨çš„é—®é¢˜

è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„ä¸­æ–‡è¡¨è¾¾ï¼Œé€‚åˆåŒ»å­¦ç”Ÿç†è§£ã€‚

è®ºæ–‡å†…å®¹ï¼ˆéƒ¨åˆ†ï¼‰ï¼š
{text[:6000]}...
"""
        
        return self.call_openrouter_api(prompt, model)
    
    def generate_reading_questions(self, text: str, research_topic: str, model: str) -> str:
        """
        ç”Ÿæˆé˜…è¯»é—®é¢˜
        
        Args:
            text: è®ºæ–‡æ–‡æœ¬
            research_topic: ç ”ç©¶ä¸»é¢˜
            model: ä½¿ç”¨çš„æ¨¡å‹
            
        Returns:
            é˜…è¯»é—®é¢˜åˆ—è¡¨
        """
        prompt = f"""
åŸºäºè¿™ç¯‡åŒ»å­¦æ–‡çŒ®å’Œç”¨æˆ·çš„ç ”ç©¶ä¸»é¢˜"{research_topic}"ï¼Œè¯·è®¾è®¡ä¸€ç³»åˆ—é˜…è¯»é—®é¢˜æ¥å¸®åŠ©åŒ»å­¦ç”Ÿæ·±å…¥ç†è§£å’Œæ‰¹åˆ¤æ€§åˆ†æè¿™ç¯‡è®ºæ–‡ã€‚

è¯·æä¾›ä»¥ä¸‹ç±»å‹çš„é—®é¢˜ï¼š

1. **ç†è§£æ€§é—®é¢˜ï¼ˆ5-6ä¸ªï¼‰**
   - æ£€éªŒå¯¹è®ºæ–‡ä¸»è¦å†…å®¹çš„ç†è§£
   - åŒ…æ‹¬ç ”ç©¶ç›®çš„ã€æ–¹æ³•ã€ç»“æœã€ç»“è®º

2. **åˆ†ææ€§é—®é¢˜ï¼ˆ4-5ä¸ªï¼‰**
   - å¼•å¯¼å­¦ç”Ÿåˆ†æç ”ç©¶è®¾è®¡çš„ä¼˜ç¼ºç‚¹
   - è¯„ä¼°è¯æ®è´¨é‡å’Œç»“è®ºçš„å¯é æ€§

3. **åº”ç”¨æ€§é—®é¢˜ï¼ˆ3-4ä¸ªï¼‰**
   - å¦‚ä½•å°†ç ”ç©¶ç»“æœåº”ç”¨åˆ°ä¸´åºŠå®è·µ
   - å¯¹ç”¨æˆ·ç ”ç©¶ä¸»é¢˜çš„å¯ç¤º

4. **æ‰¹åˆ¤æ€§é—®é¢˜ï¼ˆ3-4ä¸ªï¼‰**
   - ç ”ç©¶çš„å±€é™æ€§å’Œåå€šé£é™©
   - ä¸å…¶ä»–ç ”ç©¶çš„æ¯”è¾ƒ
   - æœªæ¥ç ”ç©¶æ–¹å‘

æ¯ä¸ªé—®é¢˜éƒ½åº”è¯¥ï¼š
- ç”¨ä¸­æ–‡è¡¨è¿°
- å…·æœ‰ä¸€å®šçš„æ€è€ƒæ·±åº¦
- ä¸ç ”ç©¶ä¸»é¢˜ç›¸å…³

è®ºæ–‡å†…å®¹ï¼ˆéƒ¨åˆ†ï¼‰ï¼š
{text[:6000]}...
"""
        
        return self.call_openrouter_api(prompt, model)
    
    def identify_key_paragraphs(self, text: str, research_topic: str, model: str) -> str:
        """
        è¯†åˆ«éœ€è¦ç²¾è¯»çš„å…³é”®æ®µè½
        
        Args:
            text: è®ºæ–‡æ–‡æœ¬
            research_topic: ç ”ç©¶ä¸»é¢˜
            model: ä½¿ç”¨çš„æ¨¡å‹
            
        Returns:
            å…³é”®æ®µè½æ¨è
        """
        prompt = f"""
ä½œä¸ºåŒ»å­¦æ–‡çŒ®åˆ†æä¸“å®¶ï¼Œè¯·ä»è¿™ç¯‡è®ºæ–‡ä¸­è¯†åˆ«å‡ºæœ€å€¼å¾—ç²¾è¯»çš„æ®µè½ï¼Œç‰¹åˆ«æ˜¯ä¸ç ”ç©¶ä¸»é¢˜"{research_topic}"æœ€ç›¸å…³çš„éƒ¨åˆ†ã€‚

è¯·æä¾›ï¼š

1. **æœ€é‡è¦çš„5-8ä¸ªæ®µè½**
   å¯¹æ¯ä¸ªæ®µè½ï¼š
   - ç®€è¦è¯´æ˜æ®µè½ä½ç½®ï¼ˆå¦‚"æ‘˜è¦ç¬¬2æ®µ"ã€"è®¨è®ºéƒ¨åˆ†ç¬¬3æ®µ"ï¼‰
   - è§£é‡Šä¸ºä»€ä¹ˆè¿™ä¸ªæ®µè½é‡è¦
   - ä¸ç ”ç©¶ä¸»é¢˜çš„å…³è”æ€§
   - é˜…è¯»æ—¶åº”è¯¥æ³¨æ„çš„è¦ç‚¹

2. **ç²¾è¯»å»ºè®®**
   - è¿™äº›æ®µè½çš„æœ€ä½³é˜…è¯»é¡ºåº
   - éœ€è¦å¯¹ç…§é˜…è¯»çš„æ®µè½ç»„åˆ
   - é˜…è¯»æ—¶åº”è¯¥åšçš„ç¬”è®°è¦ç‚¹

3. **è·³è¯»å»ºè®®**
   - å¯ä»¥å¿«é€Ÿæµè§ˆçš„éƒ¨åˆ†
   - ä¸å½“å‰ç ”ç©¶ä¸»é¢˜å…³è”åº¦è¾ƒä½çš„ç« èŠ‚

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶ä¸”å…·ä½“æŒ‡å‡ºæ®µè½å†…å®¹çš„å‰å‡ ä¸ªè¯ï¼Œä¾¿äºå®šä½ã€‚

è®ºæ–‡å†…å®¹ï¼š
{text[:8000]}...
"""
        
        return self.call_openrouter_api(prompt, model)
    
    def generate_comprehensive_report(self, pdf_path: str, research_topic: str, 
                                    model: str = "anthropic/claude-3-haiku") -> Dict[str, str]:
        """
        ç”Ÿæˆå®Œæ•´çš„æ–‡çŒ®åˆ†ææŠ¥å‘Š
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            research_topic: ç ”ç©¶ä¸»é¢˜
            model: ä½¿ç”¨çš„æ¨¡å‹
            
        Returns:
            åŒ…å«æ‰€æœ‰åˆ†æç»“æœçš„å­—å…¸
        """
        print("æ­£åœ¨æå–PDFæ–‡æœ¬...")
        full_text = self.extract_text_from_pdf(pdf_path)
        
        if len(full_text.strip()) == 0:
            raise Exception("PDFæ–‡ä»¶ä¸­æ²¡æœ‰æå–åˆ°æ–‡æœ¬å†…å®¹ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºæ‰«æç‰ˆPDF")
        
        print(f"æ–‡æœ¬æå–å®Œæˆï¼Œå…± {len(full_text)} ä¸ªå­—ç¬¦")
        
        # å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œä½¿ç”¨å‰åŠéƒ¨åˆ†è¿›è¡Œåˆ†æ
        analysis_text = full_text[:12000] if len(full_text) > 12000 else full_text
        
        results = {}
        
        print("æ­£åœ¨ç”Ÿæˆè®ºæ–‡å¤§çº²...")
        outline_data = self.analyze_paper_structure(analysis_text, research_topic, model)
        results["outline"] = outline_data["outline"]
        
        print("æ­£åœ¨ç”Ÿæˆé˜…è¯»æŒ‡å¯¼...")
        results["reading_guide"] = self.generate_reading_guide(analysis_text, research_topic, model)
        
        print("æ­£åœ¨ç”Ÿæˆé˜…è¯»é—®é¢˜...")
        results["reading_questions"] = self.generate_reading_questions(analysis_text, research_topic, model)
        
        print("æ­£åœ¨è¯†åˆ«å…³é”®æ®µè½...")
        results["key_paragraphs"] = self.identify_key_paragraphs(analysis_text, research_topic, model)
        
        results["metadata"] = {
            "pdf_path": pdf_path,
            "research_topic": research_topic,
            "model_used": model,
            "analysis_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "text_length": len(full_text)
        }
        
        return results
    
    def save_report_to_file(self, results: Dict[str, str], output_path: str):
        """
        å°†åˆ†æç»“æœä¿å­˜åˆ°æ–‡ä»¶
        
        Args:
            results: åˆ†æç»“æœå­—å…¸
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# åŒ»å­¦æ–‡çŒ®é˜…è¯»åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**åˆ†ææ—¶é—´**: {results['metadata']['analysis_date']}\n")
            f.write(f"**PDFæ–‡ä»¶**: {results['metadata']['pdf_path']}\n")
            f.write(f"**ç ”ç©¶ä¸»é¢˜**: {results['metadata']['research_topic']}\n")
            f.write(f"**ä½¿ç”¨æ¨¡å‹**: {results['metadata']['model_used']}\n")
            f.write(f"**æ–‡æœ¬é•¿åº¦**: {results['metadata']['text_length']} å­—ç¬¦\n\n")
            f.write("---\n\n")
            
            f.write("## ğŸ“‹ è®ºæ–‡å¤§çº²\n\n")
            f.write(results["outline"])
            f.write("\n\n---\n\n")
            
            f.write("## ğŸ“š é˜…è¯»æŒ‡å¯¼\n\n")
            f.write(results["reading_guide"])
            f.write("\n\n---\n\n")
            
            f.write("## â“ é˜…è¯»é—®é¢˜\n\n")
            f.write(results["reading_questions"])
            f.write("\n\n---\n\n")
            
            f.write("## ğŸ¯ ç²¾è¯»æ®µè½æ¨è\n\n")
            f.write(results["key_paragraphs"])
            f.write("\n\n")


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥é…ç½®
    if not PDF_FILE_PATH or PDF_FILE_PATH == "example_paper.pdf":
        print("âŒ è¯·åœ¨è„šæœ¬é¡¶éƒ¨çš„é…ç½®åŒºåŸŸè®¾ç½®PDF_FILE_PATH")
        print("ğŸ“ ç¼–è¾‘è„šæœ¬ï¼Œæ‰¾åˆ°'ç”¨æˆ·é…ç½®åŒºåŸŸ'ï¼Œå¡«å†™æ­£ç¡®çš„PDFæ–‡ä»¶è·¯å¾„")
        sys.exit(1)
    
    if not API_KEY or API_KEY == "sk-or-your-api-key-here":
        print("âŒ è¯·åœ¨è„šæœ¬é¡¶éƒ¨çš„é…ç½®åŒºåŸŸè®¾ç½®API_KEY")
        print("ğŸ“ ç¼–è¾‘è„šæœ¬ï¼Œæ‰¾åˆ°'ç”¨æˆ·é…ç½®åŒºåŸŸ'ï¼Œå¡«å†™ä½ çš„OpenRouter APIå¯†é’¥")
        sys.exit(1)
    
    if not RESEARCH_TOPIC:
        print("âŒ è¯·åœ¨è„šæœ¬é¡¶éƒ¨çš„é…ç½®åŒºåŸŸè®¾ç½®RESEARCH_TOPIC")
        print("ğŸ“ ç¼–è¾‘è„šæœ¬ï¼Œæ‰¾åˆ°'ç”¨æˆ·é…ç½®åŒºåŸŸ'ï¼Œæè¿°ä½ çš„ç ”ç©¶ä¸»é¢˜")
        sys.exit(1)
    
    # æ£€æŸ¥PDFæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    pdf_path = Path(PDF_FILE_PATH)
    if not pdf_path.exists():
        print(f"âŒ é”™è¯¯: PDFæ–‡ä»¶ '{PDF_FILE_PATH}' ä¸å­˜åœ¨")
        print("ğŸ“ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        sys.exit(1)
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä¸è¾“å…¥æ–‡ä»¶ç›¸åŒç›®å½•ï¼‰
    output_path = pdf_path.parent / f"{pdf_path.stem}_é˜…è¯»åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    
    try:
        # åˆå§‹åŒ–é˜…è¯»åŠ©æ‰‹
        reader = MedicalPaperReader(API_KEY, BASE_URL)
        
        print("ğŸ¥ åŒ»å­¦æ–‡çŒ®é˜…è¯»åŠ©æ‰‹")
        print("=" * 60)
        print(f"ğŸ“„ PDFæ–‡ä»¶: {PDF_FILE_PATH}")
        print(f"ğŸ”¬ ç ”ç©¶ä¸»é¢˜: {RESEARCH_TOPIC}")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {MODEL}")
        print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_path}")
        print("=" * 60)
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        results = reader.generate_comprehensive_report(
            PDF_FILE_PATH, 
            RESEARCH_TOPIC, 
            MODEL
        )
        
        # ä¿å­˜ç»“æœ
        reader.save_report_to_file(results, str(output_path))
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        print("\nğŸ“‹ ç”Ÿæˆçš„å†…å®¹åŒ…æ‹¬:")
        print("  â€¢ ğŸ“Š ä¸­æ–‡è®ºæ–‡å¤§çº²")
        print("  â€¢ ğŸ“š ä¸ªæ€§åŒ–é˜…è¯»æŒ‡å¯¼") 
        print("  â€¢ â“ æ·±åº¦æ€è€ƒé—®é¢˜")
        print("  â€¢ ğŸ¯ ç²¾è¯»æ®µè½æ¨è")
        print("\nğŸ’¡ æç¤º: å¯ä»¥ç”¨Markdownç¼–è¾‘å™¨æˆ–ç¬”è®°è½¯ä»¶æ‰“å¼€åˆ†ææŠ¥å‘Š")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("\nğŸ”§ å¸¸è§è§£å†³æ–¹æ¡ˆ:")
        print("  â€¢ æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥")
        print("  â€¢ ç¡®è®¤PDFæ–‡ä»¶ä¸æ˜¯æ‰«æç‰ˆ")
        print("  â€¢ å°è¯•ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹ï¼ˆå¦‚claude-3-haikuï¼‰")
        sys.exit(1)


if __name__ == "__main__":
    main()