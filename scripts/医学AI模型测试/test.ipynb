{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BioGptTokenizer, BioGptForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BioGptForCausalLM.from_pretrained(\"microsoft/biogpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "generate = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'COVID is caused by SARS-CoV-2, a virus transmitted through respiratory contact with a symptomatic'},\n",
       " {'generated_text': 'COVID is an infection whose clinical manifestations have a number of similarities to other acute infectious diseases such as'},\n",
       " {'generated_text': 'COVID is considered one of the most challenging pandemic diseases due to its highly contagious, highly infectious nature'},\n",
       " {'generated_text': 'COVID is characterized by progressive respiratory failure and multi-organ involvement due to infection with Severe Acute Respiratory'},\n",
       " {'generated_text': 'COVID is an illness caused by a severe respiratory disorder known as COVID-19.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate('COVID is',max_length = 20,num_return_sequences = 5,do_sample = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的文本：\n",
      "， 。??? [(Zn + (0) - Pb] + (0),) was found to be very sensitive enough in detection of lead at concentrations below 1 µg L (-1).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 加载 BioGPT 模型和分词器\n",
    "model_name = \"microsoft/BioGPT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 优化后的提示词\n",
    "prompt = \"请用简单的语言解释糖尿病是什么，并举例说明其常见症状。\"\n",
    "\n",
    "# 生成内容\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=200, do_sample=True)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"生成的文本：\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "Explain what diabetes is in simple terms and list its common symptoms.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 加载 BioGPT 模型和分词器\n",
    "model_name = \"microsoft/BioGPT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 优化后的英文提示词\n",
    "prompt = \"Explain what diabetes is in simple terms and list its common symptoms.\"\n",
    "\n",
    "# 生成内容\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=200, do_sample=True)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "Diabetes is a condition where glucose metabolism is altered.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 加载 BioGPT 模型和分词器\n",
    "model_name = \"microsoft/BioGPT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 优化后的英文提示词\n",
    "prompt = (\n",
    "    \"Diabetes is a condition where\"\n",
    ")\n",
    "\n",
    "# 生成内容\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=200,\n",
    "    temperature=0.8,  # 增加随机性\n",
    "    top_p=0.9,        # 使用 top-p 采样\n",
    "    do_sample=True    # 启用采样模式\n",
    ")\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "Diabetes is caused by a progressive decrease in the insulin concentration in the blood.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 加载 BioGPT 模型和分词器\n",
    "model_name = \"microsoft/BioGPT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 优化后的英文提示词\n",
    "prompt = (\n",
    "    \"Diabetes is caused by\"\n",
    ")\n",
    "\n",
    "# 生成内容\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=200,\n",
    "    temperature=0.8,  # 增加随机性\n",
    "    top_p=0.9,        # 使用 top-p 采样\n",
    "    do_sample=True    # 启用采样模式\n",
    ")\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "Diabetes is treated by insulin injection, but insulin therapy is costly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 加载 BioGPT 模型和分词器\n",
    "model_name = \"microsoft/BioGPT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 优化后的英文提示词\n",
    "prompt = (\n",
    "    \"Diabetes is treated by\"\n",
    ")\n",
    "\n",
    "# 生成内容\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=200,\n",
    "    temperature=0.8,  # 增加随机性\n",
    "    top_p=0.9,        # 使用 top-p 采样\n",
    "    do_sample=True    # 启用采样模式\n",
    ")\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义和解释\n",
    "\"word is\"\n",
    "\n",
    "\"word is a condition where\"\n",
    "\n",
    "\"word is defined as\"\n",
    "\n",
    "\"word refers to\"\n",
    "\n",
    "\"word is characterized by\"\n",
    "\n",
    "2. 症状描述\n",
    "\"The symptoms of word include\"\n",
    "\n",
    "\"Common signs of word are\"\n",
    "\n",
    "\"word can cause\"\n",
    "\n",
    "\"The effects of word are\"\n",
    "\n",
    "\"word is associated with\"\n",
    "\n",
    "3. 病因和机制\n",
    "\"word is caused by\"\n",
    "\n",
    "\"The main cause of word is\"\n",
    "\n",
    "\"word occurs when\"\n",
    "\n",
    "\"The mechanism behind word is\"\n",
    "\n",
    "\"word develops because\"\n",
    "\n",
    "4. 治疗方法\n",
    "\"word is treated by\"\n",
    "\n",
    "\"The treatment for word involves\"\n",
    "\n",
    "\"word can be managed with\"\n",
    "\n",
    "\"Common therapies for word include\"\n",
    "\n",
    "\"The standard approach to treating word is\"\n",
    "\n",
    "5. 药物信息\n",
    "\"word is a medication used to\"\n",
    "\n",
    "\"The primary use of word is\"\n",
    "\n",
    "\"word works by\"\n",
    "\n",
    "\"The side effects of word include\"\n",
    "\n",
    "\"word is commonly prescribed for\"\n",
    "\n",
    "6. 诊断方法\n",
    "\"word is diagnosed by\"\n",
    "\n",
    "\"The diagnosis of word involves\"\n",
    "\n",
    "\"Common tests for word include\"\n",
    "\n",
    "\"word can be detected through\"\n",
    "\n",
    "\"The criteria for diagnosing word are\"\n",
    "\n",
    "7. 预防措施\n",
    "\"word can be prevented by\"\n",
    "\n",
    "\"The best way to avoid word is\"\n",
    "\n",
    "\"Preventive measures for word include\"\n",
    "\n",
    "\"Reducing the risk of word involves\"\n",
    "\n",
    "\"word prevention focuses on\"\n",
    "\n",
    "8. 研究和发展\n",
    "\"Recent research on word suggests\"\n",
    "\n",
    "\"A potential treatment for word is\"\n",
    "\n",
    "\"The future of word research involves\"\n",
    "\n",
    "\"New developments in word treatment include\"\n",
    "\n",
    "\"A breakthrough in understanding word is\"\n",
    "\n",
    "9. 流行病学\n",
    "\"word is most common in\"\n",
    "\n",
    "\"The prevalence of word is\"\n",
    "\n",
    "\"word affects approximately\"\n",
    "\n",
    "\"The incidence of word has\"\n",
    "\n",
    "\"word is more likely to occur in\"\n",
    "\n",
    "10. 患者教育\n",
    "\"If you have word, you should\"\n",
    "\n",
    "\"Living with word requires\"\n",
    "\n",
    "\"Patients with word often experience\"\n",
    "\n",
    "\"Managing word involves\"\n",
    "\n",
    "\"The impact of word on daily life is\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
