---
title: MONAI 2Dåˆ†å‰²å­¦ä¹ æŒ‡å—
created: 2025-08-16
source: Cherry Studio
tags: 
---
## ğŸ¤– Assistant

éå¸¸æŠ±æ­‰ï¼Œæˆ‘ä¹‹å‰çš„å›ç­”å¯èƒ½é€ æˆäº†è¯¯è§£ï¼ä½ è¯´å¾—å¯¹ï¼Œä½ æä¾›çš„ GitHub é“¾æ¥æ˜¯ MONAI 2D åˆ†å‰²çš„æ•™ç¨‹ï¼Œä½†é‡Œé¢çš„æ–‡ä»¶æ•°é‡å’Œæˆ‘ä¹‹å‰ç†è§£çš„ä¸å¤ªä¸€æ ·ã€‚

ä½ æä¾›çš„å››ä¸ª Python æ–‡ä»¶åˆ†åˆ«æ˜¯ï¼š

1. `unet_evaluation_array.py`
2. `unet_evaluation_dict.py`
3. `unet_training_array.py`
4. `unet_training_dict.py`

è¿™äº›æ–‡ä»¶å®é™…ä¸Šå·²ç»**åŒ…å«äº†è®­ç»ƒå’Œè¯„ä¼°çš„å®Œæ•´é€»è¾‘**ï¼Œåªæ˜¯å®ƒä»¬è¢«åˆ†æˆäº†ä¸¤ä¸ªä¸»è¦çš„ä»»åŠ¡ï¼š**è®­ç»ƒ**å’Œ**è¯„ä¼°**ï¼Œå¹¶ä¸”é’ˆå¯¹ä¸¤ç§ä¸åŒçš„æ•°æ®å¤„ç†æ–¹å¼ï¼š**Array-based** å’Œ **Dict-based**ã€‚

**æ ¸å¿ƒè§£é‡Šï¼š**

* **`unet_training_array.py` å’Œ `unet_training_dict.py`:** è¿™ä¸¤ä¸ªæ–‡ä»¶è´Ÿè´£**è®­ç»ƒ**ä¸€ä¸ª UNet æ¨¡å‹ã€‚
 * `_array` ç‰ˆæœ¬ä½¿ç”¨äº† MONAI çš„ Map-style `ArrayDataset`ï¼Œç›´æ¥ä¼ é€’ NumPy æ•°ç»„æˆ– PIL Image å¯¹è±¡ã€‚
 * `_dict` ç‰ˆæœ¬ä½¿ç”¨äº† MONAI çš„ Map-style `Dataset`ï¼Œé…åˆ `LoadImaged` ç­‰ Dict-based transformsï¼Œå¤„ç†çš„æ˜¯å­—å…¸å½¢å¼çš„æ•°æ®ï¼Œé”®å€¼å¯¹ä¼šæ˜ç¡®å®šä¹‰ã€‚
* **`unet_evaluation_array.py` å’Œ `unet_evaluation_dict.py`:** è¿™ä¸¤ä¸ªæ–‡ä»¶è´Ÿè´£**è¯„ä¼°**ä¸€ä¸ª*.pth*æ–‡ä»¶ä¸­ä¿å­˜çš„ã€**å·²ç»è®­ç»ƒå¥½çš„ UNet æ¨¡å‹**ã€‚å®ƒä»¬ä½¿ç”¨ä¸è®­ç»ƒæ–‡ä»¶ç›¸å¯¹åº”çš„åŠ è½½æ–¹å¼ï¼ˆ`_array` æˆ– `_dict`ï¼‰æ¥åŠ è½½æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œå¹¶è®¡ç®— Dice æŒ‡æ ‡ã€‚

**å¦‚ä½•è¿è¡Œè¿™ä¸ªé¡¹ç›®ï¼š**

è¿™ä¸ªé¡¹ç›®çš„ä»£ç å·²ç»è¢«ç»„ç»‡å¾—ç›¸å½“å®Œå–„ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œã€‚æ ¸å¿ƒæµç¨‹æ˜¯ï¼š

1. **ç”Ÿæˆåˆæˆæ•°æ®**: ä»£ç é¦–å…ˆä¼šåˆ›å»ºä¸€ä¸ªä¸´æ—¶ç›®å½•ï¼Œå¹¶ç”Ÿæˆä¸€äº›åˆæˆçš„ 2D åŒ»å­¦å›¾åƒå’Œå¯¹åº”çš„åˆ†å‰²æ©ç ã€‚
2. **å®šä¹‰æ•°æ®åŠ è½½å’Œé¢„å¤„ç†**: æ ¹æ®æ˜¯ `_array` è¿˜æ˜¯ `_dict` ç‰ˆæœ¬ï¼Œä¼šå®šä¹‰ç›¸åº”çš„ `transforms` æ¥åŠ è½½å’Œé¢„å¤„ç†è¿™äº›æ•°æ®ã€‚
3. **æ„å»ºæ¨¡å‹**: å®šä¹‰ä¸€ä¸ª UNet æ¨¡å‹ã€‚
4. **è®­ç»ƒæ¨¡å‹ (å½“è¿è¡Œ `_training.py` æ–‡ä»¶æ—¶)**:
 * å°†æ•°æ®åŠ è½½åˆ° `DataLoader`ã€‚
 * å®šä¹‰æŸå¤±å‡½æ•° (Dice Loss) å’Œä¼˜åŒ–å™¨ (Adam)ã€‚
 * æ‰§è¡Œè®­ç»ƒå¾ªç¯ï¼šå‰å‘ä¼ æ’­ã€è®¡ç®—æŸå¤±ã€åå‘ä¼ æ’­ã€æ›´æ–°å‚æ•°ã€‚
 * åœ¨æ¯ä¸ªéªŒè¯é—´éš”ï¼Œè¿›è¡Œæ¨¡å‹è¯„ä¼°ï¼Œå¹¶ä¿å­˜è¡¨ç°æœ€å¥½çš„æ¨¡å‹ï¼ˆ`best_metric_model_segmentation2d_array.pth` æˆ– `best_metric_model_segmentation2d_dict.pth`ï¼‰ã€‚
 * å¯ä»¥ä½¿ç”¨ TensorBoard è¿›è¡Œå¯è§†åŒ–ã€‚
5. **è¯„ä¼°æ¨¡å‹ (å½“è¿è¡Œ `_evaluation.py` æ–‡ä»¶æ—¶)**:
 * åŠ è½½é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ã€‚
 * å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ (`model.eval()`)ã€‚
 * ä½¿ç”¨ `sliding_window_inference` è¿›è¡Œé«˜æ•ˆçš„æ¨ç†ï¼Œå°¤å…¶é€‚ç”¨äºè¾“å…¥å›¾åƒæ¯”æ¨¡å‹æ¥å—çš„ ROI å¤§å¾ˆå¤šçš„æƒ…å†µã€‚
 * è®¡ç®— Dice æŒ‡æ ‡ï¼Œå¹¶ä¿å­˜æ¨ç†ç»“æœã€‚

**é‡å†™ä¸€ä»½æ›´è¯¦ç»†çš„æŒ‡å¯¼æ–‡ä»¶ï¼Œèšç„¦äºå¦‚ä½•ç†è§£å’Œè¿è¡Œè¿™äº›æ–‡ä»¶ï¼š**

---

## MONAI 2D åˆ†å‰²æ•™ç¨‹å­¦ä¹ æŒ‡å— (è¿›é˜¶ç‰ˆ)

**é¡¹ç›®åœ°å€:** [https://github.com/Project-MONAI/tutorials/tree/master/2d_segmentation/torch](https://github.com/Project-MONAI/tutorials/tree/master/2d_segmentation/torch)

**æ ¸å¿ƒç›®æ ‡:** ç†è§£å¹¶æˆåŠŸè¿è¡Œ MONAI æä¾›çš„ 2D åŒ»å­¦å›¾åƒåˆ†å‰²è®­ç»ƒå’Œè¯„ä¼°æµç¨‹ï¼ŒæŒæ¡ Array-based å’Œ Dict-based æ•°æ®å¤„ç†ä¸¤ç§æ–¹å¼çš„åŒºåˆ«ï¼Œå¹¶å­¦ä¹  UNet æ¨¡å‹åœ¨ MONAI ä¸­çš„åº”ç”¨ã€‚

---

### ç¬¬ä¸€éƒ¨åˆ†ï¼šé¡¹ç›®æ¦‚è§ˆä¸è¿è¡Œå‰å‡†å¤‡

1. **ç†è§£é¡¹ç›®æ–‡ä»¶:**
 * **`unet_training_array.py`**: ä½¿ç”¨ **Array-based** æ•°æ®åŠ è½½æ–¹å¼è¿›è¡Œ UNet æ¨¡å‹**è®­ç»ƒ**ã€‚
 * **`unet_training_dict.py`**: ä½¿ç”¨ **Dict-based** æ•°æ®åŠ è½½æ–¹å¼è¿›è¡Œ UNet æ¨¡å‹**è®­ç»ƒ**ã€‚
 * **`unet_evaluation_array.py`**: ä½¿ç”¨ **Array-based** æ•°æ®åŠ è½½æ–¹å¼**è¯„ä¼°**å·²è®­ç»ƒå¥½çš„ UNet æ¨¡å‹ã€‚
 * **`unet_evaluation_dict.py`**: ä½¿ç”¨ **Dict-based** æ•°æ®åŠ è½½æ–¹å¼**è¯„ä¼°**å·²è®­ç»ƒå¥½çš„ UNet æ¨¡å‹ã€‚

2. **ç¯å¢ƒå®‰è£…:**
 * ç¡®ä¿ä½ å·²å®‰è£… Pythonã€PyTorch å’Œ MONAIã€‚
 * æ¨èæ‹¥æœ‰ NVIDIA GPU ä»¥åŠ é€Ÿè®­ç»ƒå’Œæ¨ç†ã€‚
 * **æŸ¥çœ‹ `requirements.txt` (å¦‚æœå­˜åœ¨)** æˆ–æ ¹æ® MONAI å®˜æ–¹æ–‡æ¡£å®‰è£…æ‰€éœ€çš„å…¶ä»–åº“ã€‚
 * **ä»£ç ä¸­å·²åŒ…å« `monai.config.print_config()`**ï¼Œè¿è¡Œä»£ç æ—¶ä¼šæ‰“å°å‡º MONAI çš„é…ç½®ä¿¡æ¯ï¼Œå¯ä»¥ç”¨æ¥æ£€æŸ¥ç¯å¢ƒæ˜¯å¦æ­£ç¡®ã€‚

3. **ç†è§£æ•°æ®ç”Ÿæˆ:**
 * æ‰€æœ‰è„šæœ¬çš„å¼€å¤´éƒ½ä¼šä½¿ç”¨ `create_test_image_2d(128, 128, num_seg_classes=1)` ç”Ÿæˆåˆæˆçš„ 128x128 å¤§å°çš„å›¾åƒå’Œæ©ç ã€‚
 * è¿™äº›å›¾åƒæ˜¯ PNG æ ¼å¼ï¼Œä¿å­˜åœ¨ä¸€ä¸ªä¸´æ—¶çš„ç›®å½•ä¸­ã€‚
 * **æ³¨æ„**: `create_test_image_2d` ç”Ÿæˆçš„åˆ†å‰²æ©ç çš„å€¼å¯èƒ½æ˜¯ 0 æˆ– 1ï¼ˆå¦‚æœæ˜¯ `num_seg_classes=2`ï¼‰ï¼Œä»£ç ä¸­ `ScaleIntensity()` ä¼šå°†å…¶ç¼©æ”¾åˆ° 0-1 èŒƒå›´ï¼Œå¹¶ä¸å›¾åƒä¸€èµ·ä¿å­˜ä¸º 0-255 çš„ uint8 å›¾åƒã€‚

### ç¬¬äºŒéƒ¨åˆ†ï¼šå­¦ä¹ ä¸è¿è¡Œ `unet_training_array.py` å’Œ `unet_training_dict.py` (è®­ç»ƒè„šæœ¬)

**ç›®æ ‡:** ç†è§£å¦‚ä½•ä½¿ç”¨ MONAI è®­ç»ƒä¸€ä¸ª UNet æ¨¡å‹è¿›è¡Œ 2D åˆ†å‰²ã€‚

#### 1. æ•°æ®åŠ è½½ä¸å¤„ç† (æ ¸å¿ƒåŒºåˆ«ç‚¹)

* **`unet_training_array.py` (Array-based):**
 * **æ•°æ®ç»„ç»‡:** ä½¿ç”¨ Python çš„ `glob` æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨ (`images`, `segs`)ã€‚
 * **`ArrayDataset`:** ç›´æ¥å°†å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨å’Œå¯¹åº”çš„ transforms ä¼ é€’ç»™ `ArrayDataset`ã€‚
 * **Transfoms:**
 * `LoadImage(image_only=True, ensure_channel_first=True)`: åŠ è½½ PNG å›¾ç‰‡ï¼Œå¹¶ç¡®ä¿é€šé“æ•°åœ¨ç¬¬ä¸€ç»´ï¼ˆä¾‹å¦‚ `[C, H, W]`ï¼‰ã€‚
 * `ScaleIntensity()`: å°†å›¾åƒåƒç´ å€¼ç¼©æ”¾åˆ° [0, 1] èŒƒå›´ã€‚
 * `RandSpatialCrop((96, 96), ...)`: éšæœºè£å‰ªå‡º 96x96 çš„åŒºåŸŸã€‚
 * `RandRotate90(...)`: éšæœºè¿›è¡Œ 90 åº¦æ—‹è½¬ã€‚
 * **`DataLoader`:** ä½¿ç”¨ `DataLoader(..., pin_memory=torch.cuda.is_available())` æ¥åŠ é€Ÿæ•°æ®åŠ è½½ã€‚

* **`unet_training_dict.py` (Dict-based):**
 * **æ•°æ®ç»„ç»‡:** åˆ›å»ºä¸€ä¸ªåŒ…å«å­—å…¸çš„åˆ—è¡¨ (`train_files`, `val_files`)ï¼Œæ¯ä¸ªå­—å…¸åŒ…å« "img" å’Œ "seg" é”®ï¼Œå€¼ä¸ºå¯¹åº”çš„æ–‡ä»¶è·¯å¾„ã€‚
 * **`Dataset`:** ä½¿ç”¨ `monai.data.Dataset`ï¼Œå¹¶å°† transforms ä½œä¸ºä¸€ä¸ªæ•´ä½“åº”ç”¨ã€‚
 * **Transfoms (with `d` suffix for Dict-based):**
 * `LoadImaged(keys=["img", "seg"])`: åŠ è½½ "img" å’Œ "seg" å¯¹åº”çš„æ–‡ä»¶ï¼Œå¹¶å°†ç»“æœå­˜å›å­—å…¸ã€‚
 * `EnsureChannelFirstd(keys=["img", "seg"])`: ENSUREé€šé“åœ¨ç¬¬0ç»´åº¦ã€‚
 * `ScaleIntensityd(keys=["img", "seg"])`: å¯¹ "img" å’Œ "seg" è¿›è¡Œç¼©æ”¾ã€‚
 * `RandCropByPosNegLabeld(...)`: **ä¸€ä¸ªæ›´é«˜çº§çš„è£å‰ªæ–¹å¼**ã€‚å®ƒä¼šæ ¹æ®æ ‡ç­¾ä¸­å‰æ™¯ï¼ˆ`pos=1`ï¼‰å’ŒèƒŒæ™¯ï¼ˆ`neg=1`ï¼‰çš„ä½ç½®æ¥é‡‡æ ·ã€‚`num_samples=4` è¡¨ç¤ºæ¯ä¸ªå­—å…¸ä¼šç”Ÿæˆ 4 ä¸ªæ ·æœ¬ã€‚**è¿™æ˜¯ Dict-based æ–¹å¼çš„ä¸€ä¸ªå…³é”®ä¼˜åŠ¿**ã€‚
 * `RandRotate90d(keys=["img", "seg"], ...)`: å¯¹å­—å…¸ä¸­çš„ "img" å’Œ "seg" è¿›è¡Œæ—‹è½¬ã€‚
 * **`list_data_collate`:** Dict-based çš„ `DataLoader` é€šå¸¸éœ€è¦ `collate_fn=list_data_collate` æ¥æ­£ç¡®å¤„ç†å­—å…¸åˆ—è¡¨ã€‚

#### 2. æ¨¡å‹ã€æŸå¤±ä¸ä¼˜åŒ–å™¨

* **æ¨¡å‹:** ä¸¤ä¸ªè„šæœ¬éƒ½ä½¿ç”¨ `monai.networks.nets.UNet`ã€‚
 * `spatial_dims=2`: å®šä¹‰ä¸º 2D æ¨¡å‹ã€‚
 * `in_channels=1`, `out_channels=1`: è¾“å…¥å’Œè¾“å‡ºé€šé“ä¸º 1 (ç°åº¦å›¾ï¼Œå•ç±»åˆ†å‰²)ã€‚
 * `channels=(16, 32, 64, 128, 256)`: UNet ç¼–ç å™¨å’Œè§£ç å™¨å„å±‚çš„å·ç§¯é€šé“æ•°ã€‚
 * `strides=(2, 2, 2, 2)`: å®šä¹‰äº†ä¸‹é‡‡æ ·/ä¸Šé‡‡æ ·çš„æ­¥é•¿ã€‚
 * `num_res_units=2`: æ¯ä¸ª Encoder/Decoder block ä¸­çš„æ®‹å·®å•å…ƒæ•°é‡ã€‚
* **æŸå¤±å‡½æ•°:** `monai.losses.DiceLoss(sigmoid=True)`ã€‚`sigmoid=True` æ„å‘³ç€æ¨¡å‹è¾“å‡ºæ˜¯ logitsï¼ŒDiceLoss ä¼šåœ¨å†…éƒ¨åº”ç”¨ Sigmoid å°†å…¶è½¬æ¢ä¸ºæ¦‚ç‡ã€‚
* **ä¼˜åŒ–å™¨:** `torch.optim.Adam(model.parameters(), 1e-3)`ã€‚

#### 3. è®­ç»ƒæµç¨‹

* **Epoch å¾ªç¯:** è¿­ä»£ 10 ä¸ª epochã€‚
* **è®­ç»ƒæ­¥:**
 * `model.train()`: è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼ã€‚
 * `optimizer.zero_grad()`: æ¸…é›¶å‰ä¸€æ­¥çš„æ¢¯åº¦ã€‚
 * `outputs = model(inputs)`: å‰å‘ä¼ æ’­ã€‚
 * `loss = loss_function(outputs, labels)`: è®¡ç®—æŸå¤±ã€‚
 * `loss.backward()`: åå‘ä¼ æ’­ã€‚
 * `optimizer.step()`: æ›´æ–°æ¨¡å‹æƒé‡ã€‚
* **éªŒè¯æ­¥ (`val_interval = 2`):**
 * `model.eval()`: è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆç¦ç”¨ dropout ç­‰ï¼‰ã€‚
 * `torch.no_grad()`: ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜å’Œè®¡ç®—ã€‚
 * `sliding_window_inference`: å½“è¾“å…¥å›¾åƒå¤§äºæ¨¡å‹æœŸæœ›çš„ ROI æ—¶ï¼Œä½¿ç”¨æ­¤å‡½æ•°è¿›è¡Œæ»‘åŠ¨çª—å£é¢„æµ‹ï¼Œä»¥é¿å…æ˜¾å­˜æº¢å‡ºå¹¶èƒ½å¤„ç†å¤§å›¾åƒã€‚`roi_size=(96, 96)` æ˜¯ UNet å®é™…å¤„ç†çš„å°ºå¯¸ï¼Œ`sw_batch_size=4` æ˜¯å¤„ç†æ»‘åŠ¨çª—å£æ—¶çš„ Mini-batch sizeã€‚
 * `post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])`: åå¤„ç†ã€‚å…ˆç”¨ Sigmoid æ¿€æ´»å°†æ¨¡å‹è¾“å‡ºï¼ˆlogitsï¼‰è½¬ä¸ºæ¦‚ç‡ï¼Œç„¶åç”¨ `AsDiscrete` å°†æ¦‚ç‡å›¾è½¬ä¸º 0/1 çš„åˆ†å‰²æ©ç ã€‚
 * `decollate_batch`: å°†æ‰¹æ¬¡å½¢å¼çš„è¾“å‡ºè½¬æ¢ä¸ºåˆ—è¡¨ï¼Œä»¥ä¾¿é€ä¸ªå¤„ç†ã€‚
 * `dice_metric(y_pred=val_outputs, y=val_labels)`: è®¡ç®— Dice æŒ‡æ ‡ï¼Œå¹¶ç´¯åŠ ã€‚
 * **ä¿å­˜æœ€ä½³æ¨¡å‹:** å¦‚æœå½“å‰ epoch çš„ Dice åˆ†æ•°é«˜äºä¹‹å‰çš„æœ€ä½³åˆ†æ•°ï¼Œåˆ™ä¿å­˜æ¨¡å‹æƒé‡åˆ° `best_metric_model_segmentation2d_array.pth` æˆ– `best_metric_model_segmentation2d_dict.pth`ã€‚
 * **TensorBoard å¯è§†åŒ–:** ä½¿ç”¨ `SummaryWriter` è®°å½•è®­ç»ƒæŸå¤±ã€éªŒè¯ Dice åˆ†æ•°ï¼Œå¹¶å¯è§†åŒ–è¾“å…¥ã€æ ‡ç­¾å’Œé¢„æµ‹ç»“æœã€‚

#### 4. å¦‚ä½•è¿è¡Œè®­ç»ƒè„šæœ¬:

1. **é€‰æ‹©ç‰ˆæœ¬:** å†³å®šæ˜¯è¦ç”¨ `_array` è¿˜æ˜¯ `_dict` ç‰ˆæœ¬ã€‚`_dict` ç‰ˆæœ¬æä¾›äº†æ›´çµæ´»çš„æ•°æ®å¤„ç†æ–¹å¼ï¼ˆå¦‚ `RandCropByPosNegLabeld`ï¼‰ã€‚
2. **å®‰è£…ä¾èµ–:** ç¡®ä¿ä½ çš„ç¯å¢ƒå·²å‡†å¤‡å¥½ã€‚
3. **è¿è¡Œå‘½ä»¤:**
 * è®­ç»ƒ Array-based: `python unet_training_array.py`
 * è®­ç»ƒ Dict-based: `python unet_training_dict.py`
4. **è§‚å¯Ÿè¾“å‡º:**
 * è„šæœ¬ä¼šæ‰“å°ç”Ÿæˆæ•°æ®çš„è·¯å¾„ã€æ¯ä¸ª epoch çš„è®­ç»ƒæŸå¤±ã€‚
 * æ¯éš” `val_interval` ä¸ª epochï¼Œä¼šæ‰“å°éªŒè¯çš„ Dice åˆ†æ•°ã€‚
 * å¦‚æœä½ çš„ç¯å¢ƒä¸­å®‰è£…äº† TensorBoard (`pip install tensorboard`)ï¼Œä½ å¯ä»¥åœ¨ç»ˆç«¯è¿è¡Œ `tensorboard --logdir runs` (å‡è®¾ `runs` æ˜¯ `SummaryWriter` é»˜è®¤çš„æ—¥å¿—ç›®å½•)ï¼Œç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—® `http://localhost:6006` æŸ¥çœ‹å¯è§†åŒ–å›¾è¡¨ã€‚
 * è®­ç»ƒå®Œæˆåï¼Œä¼šåœ¨å½“å‰ç›®å½•ä¸‹ç”Ÿæˆ `best_metric_model_segmentation2d_array.pth` æˆ– `best_metric_model_segmentation2d_dict.pth` æ–‡ä»¶ã€‚

---

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šå­¦ä¹ ä¸è¿è¡Œ `unet_evaluation_array.py` å’Œ `unet_evaluation_dict.py` (è¯„ä¼°è„šæœ¬)

**ç›®æ ‡:** ç†è§£å¦‚ä½•åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„ UNet æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨å®ƒè¿›è¡Œæ¨ç†å’Œè¯„ä¼°ã€‚

#### 1. æ•°æ®åŠ è½½ä¸å¤„ç†

* ä¸è®­ç»ƒè„šæœ¬ç±»ä¼¼ï¼Œè¿™ä¸¤ä¸ªè„šæœ¬ä¹ŸåŒºåˆ†äº† `_array` å’Œ `_dict` ä¸¤ç§åŠ è½½æ–¹å¼ã€‚
* **å…³é”®åŒºåˆ«:**
 * **ä¸åŒ…å«è®­ç»ƒçš„éšæœºå¢å¼º:** è¯„ä¼°æ—¶åªéœ€è¦ `LoadImage`/`LoadImaged` å’Œ `ScaleIntensity`/`ScaleIntensityd` è¿™æ ·çš„é¢„å¤„ç†æ­¥éª¤ã€‚
 * **`DataLoader` batch_size=1:** é€šå¸¸è¯„ä¼°æ—¶ï¼Œä¸ºäº†æ–¹ä¾¿å¤„ç†æ¯ä¸ªæ ·æœ¬å’Œ `sliding_window_inference`ï¼Œ`batch_size` è®¾ç½®ä¸º 1ã€‚
 * **`num_workers`:** `_array` ç‰ˆæœ¬ä½¿ç”¨ `num_workers=1`ï¼Œ`_dict` ç‰ˆæœ¬ä½¿ç”¨ `num_workers=4`ï¼Œè¿™ä¸å®ƒä»¬å„è‡ªçš„ `DataLoader` é…ç½®æœ‰å…³ã€‚

#### 2. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹

* **`model = UNet(...)`**: é‡æ–°å®ä¾‹åŒ–ä¸€ä¸ª UNet æ¨¡å‹ï¼Œç»“æ„è¦ä¸è®­ç»ƒæ—¶ä¸€è‡´ã€‚
* **`model.load_state_dict(torch.load("best_metric_model_segmentation2d_....pth", weights_only=True))`**: åŠ åŠ è½½ä¹‹å‰è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„æ¨¡å‹æƒé‡ã€‚`weights_only=True` æ˜¯ PyTorch 1.6+ çš„æ¨èåšæ³•ã€‚
* **`model.eval()`**: å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ã€‚

#### 3. æ¨ç†ä¸è¯„ä¼°æµç¨‹

* **`sliding_window_inference`**: åŒè®­ç»ƒè„šæœ¬ä¸€æ ·ï¼Œç”¨äºé«˜æ•ˆå¤„ç†è¾“å…¥å›¾åƒã€‚
* **`post_trans`**: åŒæ ·çš„åå¤„ç†æ­¥éª¤ï¼Œå°† logits è½¬æ¢ä¸ºäºŒå€¼åˆ†å‰²æ©ç ã€‚
* **`dice_metric`**: å®ä¾‹åŒ– `DiceMetric` æ¥è®¡ç®—è¯„ä»·æŒ‡æ ‡ã€‚
* **`saver = SaveImage(...)`**: å®ä¾‹åŒ–ä¸€ä¸ª `SaveImage` transformï¼Œç”¨äºå°†æ¨ç†ç»“æœçš„åˆ†å‰²æ©ç ä¿å­˜åˆ° `./output` ç›®å½•ä¸‹ï¼Œå¹¶è®¾ç½®äº†è¾“å‡ºæ–‡ä»¶æ‰©å±•åå’Œåç¼€ã€‚
* **ä¿å­˜è¾“å‡º:** åœ¨å¾ªç¯ä¸­ï¼Œ`saver(val_output)` ä¼šå°†æ¯ä¸ªè¾“å…¥å›¾åƒçš„åˆ†å‰²ç»“æœä¿å­˜ä¸º PNG æ–‡ä»¶ã€‚
* **æ‰“å°æœ€ç»ˆæŒ‡æ ‡:** `dice_metric.aggregate().item()` ä¼šè®¡ç®—æ‰€æœ‰æ ·æœ¬çš„å¹³å‡ Dice æŒ‡æ ‡ï¼Œå¹¶å°†å…¶æ‰“å°åˆ°æ§åˆ¶å°ã€‚
* **é‡ç½®æŒ‡æ ‡:** `dice_metric.reset()` æ¸…é™¤ç´¯ç§¯çš„æŒ‡æ ‡å€¼ï¼Œä¸ºä¸‹ä¸€æ¬¡è¿è¡Œåšå‡†å¤‡ã€‚

#### 4. å¦‚ä½•è¿è¡Œè¯„ä¼°è„šæœ¬:

1. **é¦–å…ˆï¼Œç¡®ä¿ä½ å·²ç»æˆåŠŸè¿è¡Œäº†è®­ç»ƒè„šæœ¬** (`unet_training_array.py` æˆ– `unet_training_dict.py`)ï¼Œå¹¶ä¸”åœ¨å½“å‰ç›®å½•ä¸‹ç”Ÿæˆäº†å¯¹åº”çš„ `best_metric_model_segmentation2d_....pth` æ¨¡å‹æ–‡ä»¶ã€‚
2. **é€‰æ‹©ç‰ˆæœ¬:** é€‰æ‹©ä¸ä½ è®­ç»ƒæ—¶ç›¸åŒæ–¹å¼çš„è¯„ä¼°è„šæœ¬ï¼ˆå¦‚æœä½ è®­ç»ƒæ—¶ç”¨çš„æ˜¯ `_array`ï¼Œå°±è¿è¡Œ `unet_evaluation_array.py`ï¼‰ã€‚
3. **è¿è¡Œå‘½ä»¤:**
 * è¯„ä¼° Array-based: `python unet_evaluation_array.py`
 * è¯„ä¼° Dict-based: `python unet_evaluation_dict.py`
4. **è§‚å¯Ÿè¾“å‡º:**
 * è„šæœ¬ä¼šæ‰“å°ç”Ÿæˆæ•°æ®çš„è·¯å¾„ã€‚
 * åŠ è½½æ¨¡å‹ï¼Œå¹¶è¾“å‡ºè¯„ä¼°é˜¶æ®µçš„ Dice åˆ†æ•°ã€‚
 * åœ¨å½“å‰ç›®å½•ä¸‹çš„ `./output` æ–‡ä»¶å¤¹ä¸­ï¼Œä½ ä¼šçœ‹åˆ°ä¿å­˜çš„åˆ†å‰²ç»“æœå›¾åƒã€‚

---

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šå­¦ä¹ MONAIçš„è¦ç‚¹æ€»ç»“

é€šè¿‡è¿è¡Œå’Œç†è§£è¿™å››ä¸ªè„šæœ¬ï¼Œä½ åº”è¯¥èƒ½æŒæ¡ä»¥ä¸‹ MONAI çš„å…³é”®ç‰¹æ€§ï¼š

1. **`transforms` ç³»ç»Ÿ:**
 * `Compose`: ç»„åˆå¤šä¸ª transformã€‚
 * `LoadImage`/`LoadImaged`: åŠ è½½åŒ»å­¦å›¾åƒã€‚
 * `ScaleIntensity`/`ScaleIntensityd`: å›¾åƒå¼ºåº¦å½’ä¸€åŒ–ã€‚
 * `EnsureChannelFirst`/`EnsureChannelFirstd`: ç»Ÿä¸€æ•°æ®é€šé“ç»´åº¦ã€‚
 * **æ•°æ®å¢å¼º:** `RandSpatialCrop`, `RandRotate90`, `RandCropByPosNegLabeld` ç­‰ï¼Œæ˜¯è®­ç»ƒçš„å…³é”®ã€‚
 * **åå¤„ç†:** `Activations`, `AsDiscrete` ç”¨äºå°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸ºç›‘ç£ä¿¡å·ã€‚
 * **æ•°æ®ä¿å­˜:** `SaveImage`ã€‚
2. **`Dataset` å’Œ `DataLoader`:**
 * `ArrayDataset`: é€‚ç”¨äºç›´æ¥å¤„ç†æ•°ç»„æˆ–æ–‡ä»¶è·¯å¾„çš„ Map-style datasetã€‚
 * `Dataset` (é…åˆ Dict-based transforms): é€‚ç”¨äºå¤„ç†å­—å…¸å½¢å¼æ•°æ®çš„ Map-style datasetã€‚
 * `DataLoader`: ç®¡ç†æ•°æ®æ‰¹æ¬¡åŠ è½½ï¼Œå¹¶æ”¯æŒå¤šè¿›ç¨‹æ•°æ®é¢„å– (`num_workers`)ã€‚
 * `list_data_collate`: Dict-based DataLoader éœ€è¦çš„ collate_fnã€‚
3. **æ¨¡å‹ä¸è®­ç»ƒ:**
 * `monai.networks.nets.UNet`: MONAI æä¾›çš„ UNet å®ç°ã€‚
 * `monai.losses.DiceLoss`: å¸¸è§çš„åˆ†å‰²æŸå¤±å‡½æ•°ã€‚
 * `monai.metrics.DiceMetric`: ç”¨äºè¯„ä¼°åˆ†å‰²ä»»åŠ¡çš„æŒ‡æ ‡ã€‚
4. **æ¨ç†ä¸è¯„ä¼°:**
 * `model.load_state_dict()`: åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ã€‚
 * `sliding_window_inference`: å¤„ç†å¤§å°ºå¯¸å›¾åƒçš„é«˜æ•ˆæ¨ç†æ–¹æ³•ã€‚

**è¿›ä¸€æ­¥å­¦ä¹ å»ºè®®:**

* **ä¿®æ”¹å‚æ•°:** å°è¯•ä¿®æ”¹ `batch_size`, `learning_rate`, `epochs`, `roi_size` ç­‰å‚æ•°ï¼Œè§‚å¯Ÿè®­ç»ƒå’Œè¯„ä¼°ç»“æœã€‚
* **å°è¯•ä¸åŒçš„å¢å¼º:** æ¢ç´¢ MONAI æä¾›çš„å…¶ä»– `transforms`ï¼Œå¹¶å°†å®ƒä»¬æ·»åŠ åˆ°è®­ç»ƒ pipeline ä¸­ã€‚
* **è‡ªå®šä¹‰æ•°æ®é›†:** å°è¯•å°†ä½ è‡ªå·±çš„åŒ»å­¦å›¾åƒæ•°æ®é›†æ›¿æ¢æ‰ç”Ÿæˆçš„åˆæˆæ•°æ®ã€‚ä½ éœ€è¦è°ƒæ•´æ–‡ä»¶è·¯å¾„çš„ç»„ç»‡æ–¹å¼å’Œ `transforms`ã€‚
* **ç†è§£ `RandCropByPosNegLabeld`:** è¿™æ˜¯ä¸€ä¸ªéå¸¸å®ç”¨çš„ transformï¼Œç†è§£å®ƒçš„å·¥ä½œåŸç†å¯ä»¥å¸®åŠ©ä½ æ›´å¥½åœ°å¤„ç†åˆ†å‰²ä»»åŠ¡ä¸­çš„æ ·æœ¬ä¸å¹³è¡¡é—®é¢˜ã€‚

å¸Œæœ›è¿™ä»½æ›´è¯¦ç»†çš„æŒ‡å—èƒ½å¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£å’Œè¿è¡Œ MONAI çš„ 2D åˆ†å‰²æ•™ç¨‹ï¼
